{
  "id": "958c57ec4917",
  "title": "Day 1393",
  "createdAt": "2026-01-14 04:07:21",
  "tags": [
    "ai",
    "command-line",
    "gui",
    "saas",
    "technology"
  ],
  "url": "https://chepenikconor.medium.com/day-1393-958c57ec4917",
  "content": "# Day 1393\n\n**The Chatbox Era Will Look Primitive in Five Years**\n\n![[https://x.com/ConorChepenik/status/2011277576963055900?s=20](https://x.com/ConorChepenik/status/2011277576963055900?s=20)](https://miro.medium.com/1*OpBc-sH7wrYcFIqXyd8vsw.png)\n\nGrateful I get to be on the front lines as \"software eats the world\". Like most modern software companies, Swan runs on other software. Our stack is deep. Support tools, analytics platforms, internal ops systems, CRMs, documentation tools, scheduling software, communication apps. The list goes on. I interact with dozens of third-party products every week just to do my job.\n\nWhat I've been watching since I got to Swan, but especially over the past month, is strange and fascinating. AI is being quietly inserted into almost everything I touch. It started slowly. A lot of copying and pasting emails into ChatGPT to make sure they are well written. Then our dashboard tool added a natural language developer feature. Now my boss is getting ready to teach me how to submit PRs for internal tooling. No code required, just button clicks & prompts. Our internal messaging tool, Slack, just introduced an AI bot that is just like ChatGPT. Soon I suspect our CRM will have a chatbot that could look up customer data as needed. One by one, the vendors we depend on have begun shipping more and more AI features.\n\nI find myself in an unusual position. I'm not building AI. I'm not researching AI. I'm just using software to do my work, and I'm watching the transformation happen in real time, from the inside. It's like being a passenger on a ship and noticing that the crew is slowly replacing parts of the engine while you're still at sea.\n\nTwo feelings coexist in my mind. The first is genuine wonder. This is actually happening. The technology that people have been speculating about for decades is now showing up in mundane business software. I can ask a dashboard a question in plain English and get an answer. That's remarkable.\n\nThe second feeling is harder to articulate. It's the sense that what I'm seeing is deeply provisional. These AI features are like first drafts. They work, mostly, but they also feel awkward. They feel bolted on. They feel like the software equivalent of duct tape and optimism. The more I use these tools, the more convinced I become that we are much earlier in this transition than most people realize.\n\n**The Chatbox is Lowkey a Terminal with a Sleek UI**\n\nHere is the pattern I see everywhere. A company has an existing product. They want to add AI. So they add a chatbox. The chatbox sits in the corner of the interface, or it opens in a sidebar, or it appears as a modal. You type into it. The AI responds. Sometimes it's helpful and sometimes it hallucinates. Sometimes it gives you exactly what you need. Sometimes it gives you something that looks right but is subtly wrong.\n\nThe experience is not bad, exactly. But it's not natural either. Using these AI chatboxes reminds me of using a command line. I don't think we go to Jarvis immediately, but we'll get there one day. Maybe the in-between is an agent that sees everything on my screen like I do, makes suggestions in a modal when I want them, and goes away when I don't.\n\nThe command line is a powerful interface. For decades, it was the primary way humans interacted with computers. You typed commands. The computer executed them. If you knew the right syntax, you could do almost anything. If you didn't, you were stuck.\n\nThe graphical user interface replaced the command line for most people because it lowered the barrier to entry. Walter Isaacson's book on Steve Jobs does a great job explaining how Apple changed the game with the GUI. You didn't need to memorize commands anymore. You could see your options. You could point and click. The computer became accessible to non-experts.\n\nWhat we've done with AI, so far, is bolt a command line back onto our software. The chatbox is a text input field. You have to know what to ask. You have to phrase it correctly. You have to understand what the AI can and cannot do. If you prompt it well, you get good results. If you prompt it poorly, you get garbage. Honestly, more people should be meta prompting a.k.a asking an AI to improve your initial prompt. It's a simple thing, but man I've found it to work wonders.\n\nThis is not a criticism of the people building these features. Given the current state of the technology, a chatbox is a reasonable interface choice. It's flexible. It's familiar. It ships quickly. It works. But it also seems like a temporary thing.\n\n**Prompting is an Important Skill**\n\nThere's a revealing phrase that has entered the professional vocabulary: prompt engineering. The fact that we needed to invent a term for \"knowing how to talk to AI\" tells you something about where we are. We've created systems powerful enough to be useful but opaque enough to require specialized knowledge to operate effectively.\n\nI've watched friends struggle with this. Smart, capable people who are excellent at their jobs will sit down in front of an AI chatbox and not know what to type. They'll ask vague questions and get vague answers. They'll give up and go back to doing things the old way. As the saying goes \"garbage in, garbage out\".\n\nMeanwhile, the people who have spent time learning how to prompt effectively get disproportionate value from the same tools. They know to be specific. They know to provide context. They know to ask for formats and constraints. They know to iterate. To be fair, I think younger people who haven't been taught one way have an easier time with this. It's often harder to unlearn something than it is to learn something new.\n\nThis gap is real, and it will likely grow. I guess that's good news for the kids. But, good interfaces shouldn't require users to develop specialized skills just to get basic utility. Good interfaces meet people where they are.\n\nIn many ways, the chatbox paradigm puts the burden on the user. You have to figure out how to communicate with the machine. The machine just sits there, waiting for input, like a command prompt blinking in the dark.\n\n**What Working in Software has Revealed To Me**\n\nMy vantage point inside a software company that depends on other SaaS companies gives me a particular view of this transition. I see how the sausage gets made on both sides. I see our own company wrestling with where and how to integrate AI. To be fair, I think we are doing an excellent job and I respect that my management all uses it themselves. Across the organization it seems like it has helped tremendously with people's workflows. I also see our vendors doing the same thing. I see the patterns repeating across the industry.\n\nThe pattern is this: AI gets added to existing workflows without fundamentally changing those workflows. The underlying software architecture stays the same. The user experience stays mostly the same. There's just a chatbox now. Or a \"generate\" button. Or an \"explain this\" feature.\n\nThis makes sense from a product development perspective. You can't rebuild everything at once. You have to ship incrementally. You have to validate that users want AI features before you bet the company on a complete redesign.\n\nBut it also means that what we're experiencing right now is a transition phase, not a destination. The AI is being layered on top of software that was designed for a pre-AI world. The seams are visible, and yet I'm excited to see more layers added.\n\nIt would be sweet to have the AI summarize a support ticket, but I will still have to manually update the ticket status for the time being. The AI could soon suggest a response, and if I like it I just hit tab, but the response likely won't account for context that exists elsewhere in the system until we give it more and more data.\n\nThe tools are smarter than they used to be. But they're not decision makers just yet. I do suspect they'll get there soon enough.\n\n**Speculation on What Comes Next**\n\nI don't have a crystal ball, so maybe I'll be eating some glass here shortly. But I've been thinking about what AI interfaces might look like in five years, and I want to share some intuitions. The chatbox will not disappear entirely. Natural language is a powerful and flexible input modality. But it will become one option among many, and probably not the primary one.\n\nWhat I expect to see is software that requires less explicit instruction. Right now, I have to tell the AI what to do. I have to initiate every interaction. I have to prompt. Even in Claude Code I have to hit \"Yes, run that command, don't ask again\" about 5 times in a row before it writes me some beautiful code. In five years, I think the relationship will be more reciprocal. The software will observe what I'm doing. It will notice patterns. It will anticipate needs. It will surface information before I ask for it. It will take actions on my behalf without being told, or it will propose actions and wait for confirmation.\n\nThis is not just science fiction, as pieces of this already exist. Email clients that draft replies. Calendars that suggest meeting times. Code editors that autocomplete entire functions. These are early examples of software that acts rather than waits.\n\nThe difference in five years will be the depth and integration. Right now, these proactive features are isolated. They exist in individual tools, and they don't talk to each other. Your calendar probably doesn't know what's in your email. Your CRM might not know what's in your calendar. The AI in one tool has no awareness of the AI in another tool unless you have MCP set up properly.\n\nAs these systems become more connected, the possibilities expand. Imagine software that understands not just what you're doing in one application, but what you're trying to accomplish across all of them. Software that can see the whole picture, not just fragments. That's when things get really interesting.\n\n**The Interface is the Revolution**\n\nThere's a tendency in technology discourse to focus on the wrong layer of the stack. People talk about models. They talk about parameters. They talk about benchmarks. They debate whether GPT is better than Claude or whether open source will win (right now Claude seems to be cooking GPT). They talk about compute and inference costs and training data.\n\nYet I keep coming back to the human nature aspect of all this. The revolution is in how humans interact with systems. The revolution is at the interface layer.\n\nThink about the smartphone. The hardware mattered. The software mattered. But what actually changed the world was the touchscreen. The interface. The way humans could interact with computing in a new way, one that felt natural and immediate. From what I've read, Steve Jobs designed the iPad so even a child would immediately know how to pick it up and use it. So simple, so seamless, so friendly that someone with no experience with it would feel comfortable toying around immediately.\n\nThe same will be true for AI. The models will continue to improve. Compute will get cheaper. Capabilities will expand. But the thing that actually changes how we work and live will be the interface through which we access those capabilities.\n\nRight now, that interface is primitive. We're typing into chatboxes like it's the 1970s and we just discovered the command line. It works. It's better than nothing. But it's not where this ends.\n\nThe companies that figure out the interface question will win the next decade. Not just the ones with the best models. Not the ones with the most compute. The ones who figure out how to make AI feel natural, ambient, and invisible.\n\n**The Humility of the Current Moment**\n\nI write this with humility. I don't know what the future holds. I could be wrong about all of it. But I know what I see every day at work. I see AI features that are impressive and clunky at the same time. I see tools that are clearly better than what we had before, but also clearly not what we'll have in a few years. I see the future arriving in awkward increments.\n\nWhat strikes me most is the gap between the hype and the reality. The hype says AI will transform everything. The reality is that AI is transforming things slowly, unevenly, and with a lot of friction.\n\nThat's not a reason for pessimism. That's just how technology transitions work. They take longer than you expect. They're messier than the narratives suggest. The early versions are always rougher than they seem in retrospect.\n\nI remember the early smartphone apps. They were bad. They crashed. They had terrible UX. They were slow. And yet, I was so hyped to show my friends a gun shooting on my iPad when I touched the screen. Or how I could flick a digital lighter open and light it. Such silly apps, but I loved using them.\n\nThe AI tools I use today will look similarly primitive in hindsight. The chatboxes, the prompt engineering, the bolted-on features. All of it will seem quaint.\n\nWe are early, very early. I've got no idea if there will be a big AI bubble pop or not, but either way ten years from now the world and the way we use software is going to feel completely different. Not because the models will be smarter, though they will be. But because someone will figure out the interface. Someone will crack the code on making AI feel like a natural extension of human intention rather than a tool you have to operate.\n\nWhen that happens, we'll look back at this era and wonder how we ever tolerated typing prompts into chatboxes. It will feel as alien as the command line feels to someone who grew up with touchscreens.\n\nThat moment is coming. We're just not there yet.\n\n1/13/26\n\nConor Jay Chepenik",
  "wordCount": 2359,
  "readingTime": 9.101886792452829,
  "claps": 0,
  "voters": 0
}